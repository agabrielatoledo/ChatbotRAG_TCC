{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T73vOnnPGHSy",
        "outputId": "3a619fb6-222c-4c7d-9638-688a364771c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Caminho dos Dados: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos\n",
            "Caminho do Modelo LLM: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf\n",
            "Caminho do Banco de Dados Chroma: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/chroma_db\n"
          ]
        }
      ],
      "source": [
        "# CÉLULA 1 - MONTAGEM DO GOOGLE DRIVE E DEFINIÇÃO DE CAMINHOS GLOBAIS\n",
        "from google.colab import drive #importa biblioteca para conectar Colab com Drive (onde o database está)\n",
        "drive.mount('/content/drive') #acessa meu Drive como uma pasta local\n",
        "\n",
        "# Defina os caminhos para suas pastas e arquivos no Google Drive\n",
        "  #Armazena na variável o caminho do database\n",
        "DATA_PATH = \"/content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos\"\n",
        "  #Armazena na variável o caminho do model LLM (que está no drive)\n",
        "LLAMA_MODEL_PATH = \"/content/drive/MyDrive/InfoBio/TCC 2/databaseRag/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf\"\n",
        "  #Armazena na variável o caminho onde o banco ChromaDB será salvo. O Chroma vai guardar os vetores numéricos que eram os arigos\n",
        "CHROMA_PERSIST_DIR = \"/content/drive/MyDrive/InfoBio/TCC 2/databaseRag/chroma_db\"\n",
        "\n",
        "#Printar na tela os valores das variáveis (útil para verificação, se foi linkado com sucesso)\n",
        "print(f\"Caminho dos Dados: {DATA_PATH}\")\n",
        "print(f\"Caminho do Modelo LLM: {LLAMA_MODEL_PATH}\")\n",
        "print(f\"Caminho do Banco de Dados Chroma: {CHROMA_PERSIST_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5xq_UQvu2gJ",
        "outputId": "86e92497-0606-4bfa-89a6-6ea9dbb30016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando o checksum SHA256 para: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf\n",
            "Isso pode levar um ou dois minutos para um arquivo grande...\n",
            "\n",
            "✅ Cálculo concluído!\n",
            "\n",
            "Checksum Calculado: 8ba9baf3a7345f705a11878397500fb25174034f0fd784e83aa4a96aaa47735f\n",
            "\n",
            "Checksum Oficial: 8ba9baf3a7345f705a11878397500fb25174034f0fd784e83aa4a96aaa47735f\n"
          ]
        }
      ],
      "source": [
        "# CÉLULA DE VERIFICAÇÃO DE INTEGRIDADE (CHECKSUM)\n",
        "import hashlib\n",
        "\n",
        "# Certifique-se de que a variável LLAMA_MODEL_PATH está definida com o caminho correto\n",
        "# Esta variável vem da sua Célula 1.\n",
        "model_file_path = LLAMA_MODEL_PATH\n",
        "\n",
        "# Cria um objeto hash SHA256\n",
        "sha256_hash = hashlib.sha256()\n",
        "\n",
        "print(f\"Calculando o checksum SHA256 para: {model_file_path}\")\n",
        "print(\"Isso pode levar um ou dois minutos para um arquivo grande...\")\n",
        "\n",
        "try:\n",
        "    with open(model_file_path, \"rb\") as f:\n",
        "        # Lê o arquivo em pedaços (chunks) para não sobrecarregar a memória RAM\n",
        "        for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
        "            sha256_hash.update(byte_block)\n",
        "\n",
        "    calculated_checksum = sha256_hash.hexdigest()\n",
        "    print(\"\\n✅ Cálculo concluído!\")\n",
        "    print(f\"\\nChecksum Calculado: {calculated_checksum}\")\n",
        "    print(f\"\\nChecksum Oficial: 8ba9baf3a7345f705a11878397500fb25174034f0fd784e83aa4a96aaa47735f\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"\\nERRO: Arquivo não encontrado em '{model_file_path}'. Verifique o caminho.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nOcorreu um erro: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAmZHPOcGVuR",
        "outputId": "3aaed5cf-e0e3-4391-837e-ce93b0a454cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nenhum banco de dados antigo encontrado para remover.\n"
          ]
        }
      ],
      "source": [
        "#CÉLULA 2 - REMOÇÃO DO ANTIGO BD\n",
        "\n",
        "#importa biblioteca para interagir com o sistema operacional\n",
        "import os\n",
        "#importa a biblioteca para fazer operações de alto nível em arquivos, como apagar um diretório inteiro\n",
        "import shutil\n",
        "\n",
        "\n",
        "#verifica se a pasta do banco de dados ChromaDB (definida na céula 1) já existe\n",
        "if os.path.exists(CHROMA_PERSIST_DIR): #caso exista\n",
        "    print(f\"Removendo o banco de dados antigo em: {CHROMA_PERSIST_DIR}\") #informa que será excluida\n",
        "    shutil.rmtree(CHROMA_PERSIST_DIR) #apaga a pasta e o conteúdo que houver dentro dela\n",
        "    print(\"Banco de dados antigo removido com sucesso.\")\n",
        "else: #caso não exista, apenas informa:\n",
        "    print(\"Nenhum banco de dados antigo encontrado para remover.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k3O7SuDaZ42",
        "outputId": "7018ef46-b6e7-4000-8b2a-ea7adb0d5c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "➡️ Tentando instalar llama-cpp-python a partir de uma roda pré-compilada...\n",
            "Requirement already satisfied: llama-cpp-python==0.2.77 in /usr/local/lib/python3.12/dist-packages (0.2.77)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python==0.2.77) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python==0.2.77) (2.0.2)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python==0.2.77) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python==0.2.77) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.11.3->llama-cpp-python==0.2.77) (3.0.3)\n",
            "\n",
            "✅ Verificação final da instalação:\n",
            "Name: llama_cpp_python\n",
            "Version: 0.2.77\n",
            "Summary: Python bindings for the llama.cpp library\n",
            "Home-page: https://github.com/abetlen/llama-cpp-python\n",
            "Author: \n",
            "Author-email: Andrei Betlen <abetlen@gmail.com>\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: diskcache, jinja2, numpy, typing-extensions\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "# CÉLULA 3 - INSTALAÇÃO DAS BIBLIOTECAS\n",
        "\n",
        "#instalações padrão que são rápidas:\n",
        "  # langchain -> framework principal\n",
        "  # chromaBD -> banco de dados vetorial\n",
        "  # sentence-transformers -> gerador de embeddings\n",
        "  # docx2txt, pypdf, unstructured -> processamento de documentos. (unstructured é o salvador para artigos de duas colunas etc)\n",
        "!pip install -q langchain langchain-community chromadb sentence-transformers docx2txt pypdf \"unstructured[all-docs]\"\n",
        "\n",
        "#tentativa de instalação rápida do llama-cpp-python\n",
        "print(\"➡️ Tentando instalar llama-cpp-python a partir de uma roda pré-compilada...\")\n",
        "\n",
        "#instala a biblioteca que permite rodar o modelo Llama (.guff), tentando encontrar uma versão pré compilada para acelerar o processo.\n",
        "!pip install llama-cpp-python==0.2.77 --no-cache-dir\n",
        "\n",
        "print(\"\\n✅ Verificação final da instalação:\")\n",
        "\n",
        "#exibe os detalhes do pacote para confirmar que foi instalado corretamente, e verificar a versão.\n",
        "!pip show llama-cpp-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvqH0t3JGvZT",
        "outputId": "fa871ea3-c9de-48be-e84b-932fa273fbad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo já existe em /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf. Pulando o download.\n"
          ]
        }
      ],
      "source": [
        "# CÉLULA 4 - DOWLOAD DO MODELO\n",
        "#importa biblioteca para interagir com arquivos do sistema\n",
        "import os\n",
        "\n",
        "#extrai apenas o caminho do diretório onde o arquivo do modelo deve ficar\n",
        "model_dir = os.path.dirname(LLAMA_MODEL_PATH)\n",
        "#cria a pasta do destino do modelo, caso ainda não exista\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "#define a URL de download do modelo via Huggin Face\n",
        "model_url = \"https://huggingface.co/bartowski/Llama-3-8B-Instruct-GGUF/resolve/main/Llama-3-8B-Instruct.Q4_K_M.gguf\"\n",
        "\n",
        "\n",
        "#verifica se o modelo não existe no local esperado\n",
        "if not os.path.exists(LLAMA_MODEL_PATH):\n",
        "    print(f\"Baixando modelo de {model_url}...\")\n",
        "    !wget -O \"{LLAMA_MODEL_PATH}\" \"{model_url}\" #comando para baixar o arquivo da URL e salvar no caminho definido\n",
        "    print(\"Download concluído!\")\n",
        "else: #caso já exista o modelo, pula o download e puxa da pasta do drive setada na C1.\n",
        "    print(f\"Modelo já existe em {LLAMA_MODEL_PATH}. Pulando o download.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jVEiN6vG1-A"
      },
      "outputs": [],
      "source": [
        "# CÉLULA 5 - IMPORTAÇÕES\n",
        "\n",
        "\n",
        "#biblioteca para interagir com arquivos e pastas do sistema\n",
        "import os\n",
        "import shutil\n",
        "#importa divisor de texto, que quebra documentos longos em chunks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "#importa a classe do ChromaDB, onde os chunks serão armazenados e indexados\n",
        "from langchain_community.vectorstores import Chroma\n",
        "#importa um fluxo pré construido que conecta a busca de documentos com geração de respostas pelo LLM\n",
        "from langchain.chains import RetrievalQA\n",
        "#importa o conector que permite ao LangChain usar o modelo Llama 3 do arquivo .guff\n",
        "from langchain_community.llms import LlamaCpp\n",
        "#importa ferramenta que cria templates de prompt, estrtuturando a pergunta enviada ao LLM\n",
        "from langchain.prompts import PromptTemplate\n",
        "#importa função para limpar metadados complexos\n",
        "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
        "#carregador de arquivos unstructured, possibilita a leitura de arquivos com diretos formatos **ponto chave p ler artigos cientificos e revistas\n",
        "from langchain_community.document_loaders import UnstructuredFileLoader\n",
        "#importa 'callback' para exibir a resposta do LLM em tempo real ~vai printando cfme encontra resposta~\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "#importa classe principal que carrega modelo para transformar trechos de texto em vetores numéricos (embeddings)\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGlxo0_lG658"
      },
      "outputs": [],
      "source": [
        "# CÉLULA 6 - FUNÇÕES DE CARREGAMENTO E CHUNKING\n",
        "\n",
        "\n",
        "#define a função que aceita o caminho de uma pasta como entrada\n",
        "   #Carrega documentos de uma pasta usando a biblioteca 'unstructured', que entende layouts complexos como colunas, tabelas e imagens.\n",
        "\n",
        "def load_documents_from_folder_unstructured(folder_path):\n",
        "    documents = [] #cria lista vazia para armazenamento dos elementos carregados\n",
        "    for root, _, files in os.walk(folder_path): #inicia laço que percorre todas as pastas e arquivos do caminho\n",
        "        for file in files: #inicia um segundo laço para processar cada arquivo encontrado individualmente\n",
        "            if file.startswith(\"~$\"): #verifica se é um arquivo temporário do Office (que deve ser ignorado)\n",
        "                continue #ignora os arquivos temporários e segue laço\n",
        "\n",
        "            file_path = os.path.join(root, file) #monta o caminho completo para o arquivo que será processado\n",
        "\n",
        "\n",
        "            loader = UnstructuredFileLoader( #cria carregador de arquivos unstructured para arquivo atual\n",
        "                file_path,\n",
        "                mode=\"elements\", #quebra o doc em partes lógicas (títulos, parágrafos, tabelas)\n",
        "                strategy=\"auto\"  #deixa a biblioteca escolher a melhor estratégia para extração para arquivo\n",
        "            )\n",
        "\n",
        "            try: #inicia bloco para tratamento de possíveis erros no carregamento\n",
        "                print(f\"Carregando com Unstructured: {file_path}\") #informa qual arquivo está sendo carregado no momento\n",
        "                loaded_docs = loader.load() #executa o carregamento, extraindo os elementos do arquivo\n",
        "\n",
        "                for doc in loaded_docs: #inicia laço para verificar cada elemento extraído (parágrafo, tabelas, colunas)\n",
        "                    if doc.metadata.get('category') == 'Table': #categoriza tabelas\n",
        "                        doc.page_content = f\"A seguir, uma tabela extraída do documento:\\n{doc.page_content}\"\n",
        "                documents.extend(loaded_docs) #adiciona elementos extraídos do arquivo à lista principal 'documents'\n",
        "            except Exception as e: #função para capturar possíveis erros\n",
        "                print(f\"Erro ao carregar {file_path} com Unstructured: {e}\") #informa o arquivo que falhou e o respectivo erro\n",
        "\n",
        "    print(f\"\\nCarregados {len(documents)} elementos dos documentos.\") #informa quantos elementos foram carregados\n",
        "    return documents #retorna lista completa com todos os elementos, de todos os documentos\n",
        "\n",
        "\n",
        "def split_documents_into_chunks(documents, chunk_size=800, chunk_overlap=200): #define a função para 'fatiar' documentos com valores padrão de tamanho e sobreposição\n",
        "    text_splitter = RecursiveCharacterTextSplitter( #cria o divisor de texto com as configurações especificadas\n",
        "        chunk_size=chunk_size, #define tamanho máximo de cada pedaço de texto (em caracteres)\n",
        "        chunk_overlap=chunk_overlap, #define quantos caracteres do final de um chunk se repetem no início do próximo\n",
        "        length_function=len,  #informa ao divisor para medir o tamanho dos chunks usando a função padrão len()\n",
        "        add_start_index=True, #adiciona aos metadados de cada chunk a sua posição de início no documento original.\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(documents) #executa a divisão dos documentos na lista de chunks.\n",
        "    print(f\"Documentos divididos em {len(chunks)} chunks.\") #informa o número total de chunks criados após a divisão.\n",
        "\n",
        "\n",
        "    return chunks #retorna a lista final de chunks\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnjRVTXeHJ-H"
      },
      "outputs": [],
      "source": [
        "# CÉLULA 7 -\n",
        "\n",
        "# Função 1: define a função para criar um novo banco de dados vetorial\n",
        "def create_vector_db(chunks, embedding_model_name=\"all-MiniLM-L6-v2\", persist_directory=CHROMA_PERSIST_DIR):\n",
        "    embeddings = SentenceTransformerEmbeddings(model_name=embedding_model_name) #carrega modelo que transforma texto em vetores númericos (embeddings)\n",
        "    filtered_chunks = filter_complex_metadata(chunks) #limpa os metadados dos chunks para evitar erros na criação do banco\n",
        "    print(\"Criando e persistindo o ChromaDB com metadados filtrados...\")\n",
        "    db = Chroma.from_documents( #comando principal que cria o banco de dados a partir dos documentos\n",
        "        documents=filtered_chunks, #informa quais chunks (já filtrados) devem ser adicionados ao banco\n",
        "        embedding=embeddings, #define qual modelo de embedding será usado para vetorizar os chunks\n",
        "        persist_directory=persist_directory #especifica a pasta onde o banco de dados final será salvo\n",
        "    )\n",
        "    print(f\"ChromaDB criado em: {persist_directory}\")\n",
        "    return db #retorna o obketo do banco de dados recém-criado\n",
        "\n",
        "\n",
        "#Função 2: carrega um banco de dados vetorial que já foi criado e salvo anteriormente\n",
        "def load_vector_db(embedding_model_name=\"all-MiniLM-L6-v2\", persist_directory=CHROMA_PERSIST_DIR): #define função para carregar um banco de dados que já existe\n",
        "    embeddings = SentenceTransformerEmbeddings(model_name=embedding_model_name) #carrega o mesmo modelo de embedding para entender os vetores já salvos\n",
        "    print(f\"Carregando ChromaDB de: {persist_directory}\")\n",
        "    db = Chroma(persist_directory=persist_directory, embedding_function=embeddings) #cria uma instância no ChromaDB carregando os dados da pasta específica\n",
        "    return db #retorna o objeto do banco de dados carregado, pronto para uso\n",
        "\n",
        "\n",
        "\n",
        "#Função 3: monta e conecta todos os componnetes: o LLM, o retriever e o prompt, criando o RAG final\n",
        "def setup_rag_chain(vector_db, llm_model_path): #define função que configura o fluxo de pergunta e resposta\n",
        "    llm = LlamaCpp( #carrega modelo LLama 3 com as configurações:\n",
        "        model_path=llm_model_path,\n",
        "        temperature=0.2, #mais focado, menos criativo para respostas + precisas\n",
        "        max_tokens=1024, #define o tamanho máximo da resposta gerada pelo modelo\n",
        "        n_ctx=8192, #define tamanho da 'memória' contexto que o modelo pode usar\n",
        "        n_gpu_layers=-1, #tenta usar GPU para processar o máximo de camadas do modelo, acelerando a resposta\n",
        "        verbose=False, #desativa logs internos do Llama para manter saída limpa\n",
        "        streaming=True, #ativa resposta em tempo real, palavra por palavra\n",
        "        callbacks=[StreamingStdOutCallbackHandler()] #conexação da função para exibir resposta em tempo real\n",
        "    )\n",
        "\n",
        "\n",
        "    retriever = vector_db.as_retriever( #cria o recuperador de documentos a partir do banco de dados\n",
        "        search_type=\"mmr\", #usa método MMR para buscar documentos relevantes entre si\n",
        "        search_kwargs={\"k\": 5, \"fetch_k\": 20} #configura MMR para buscar 20 chunks e selecionar os 5 melhores\n",
        "    )\n",
        "\n",
        "    #define o modelo de prompt instruindo como o LLM deve se comportar\n",
        "    prompt_template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "Você é um profissional de saúde, especialista em orientação pré e pós-operatória de cirurgia cardíaca.\n",
        "Forneça respostas padronizadas, seguras, objetivas e em linguagem acessível ao paciente. **Responda de forma direta, omitindo saudações ou introduções robóticas.** Suas orientações são estritamente baseadas no contexto fornecido.\n",
        "Se a informação for individualizada (como dosagem, diagnóstico ou liberação para atividades) ou não estiver no contexto, responda com uma das seguintes frases padronizadas:\n",
        "'Esta é uma questão específica do seu histórico médico e deve ser discutida diretamente com seu médico cardiologista ou a equipe de enfermagem.' OU 'Essa informação depende de uma avaliação individualizada.\n",
        "Por favor, consulte seu médico ou a equipe de saúde responsável.'\n",
        "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "Com base no contexto abaixo, responda à minha pergunta.\n",
        "\n",
        "Contexto:\n",
        "{context}\n",
        "\n",
        "Pergunta:\n",
        "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "    #transforma a string do prompt em um objeto que o LangChain pode usar\n",
        "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type( #cria cadeia RAG final, unindo todas as peças\n",
        "        llm=llm, #conecta LLM a cadeia\n",
        "        chain_type=\"stuff\", #define que todos os textos recuperados serão compilados no prompt de uma vez\n",
        "        retriever=retriever, #conecta o recuperador MMR a cadeia\n",
        "        return_source_documents=True, #faz com que a cadeira retorne também os trechos dos documentos usads na resposta\n",
        "        chain_type_kwargs={\"prompt\": PROMPT} #insere o prompt customizado na cadeia\n",
        "    )\n",
        "    print(\"Cadeia RAG configurada com sucesso (MMR e Streaming ativados).\")\n",
        "    return qa_chain #retorna a cadeia RAG completa e pronta para receber perguntas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qcBag38Q3cif",
        "outputId": "112e6ae5-d429-4e32-8c4b-59662f23ad26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfpage:The PDF <_io.BufferedReader name='/content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/5371-Texto do artigo-16016-1-10-20081007.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChromaDB não encontrado ou falha ao carregar. Iniciando processo de criação em diretório temporário...\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/5371-Texto do artigo-16016-1-10-20081007.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P7' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P9' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P10' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P12' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P7' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P9' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P10' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P12' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P13' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P14' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P15' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P16' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P17' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P18' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P14' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P17' is an invalid float value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No languages specified, defaulting to English.\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/4284-28572-1-PB.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/IIDD225 PDF.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/rgenfermagem,+551-556.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/35284-Texto do Artigo-253541-1-10-20241114.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/ijrb-17-883.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/ali,+2+CUIDADOS+DE+ENFERMAGEM+A+PACIENTES+EM+PRÉ-OPERATÓRIO+PROPOSTA+DE+CHECKLIST.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/afab146.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/submetido-ARTIGO+CIRURGIA+CARDÍACA (1).pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/download.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/scopusresults.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/artigo scopus.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/artigo download.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/faqTabela.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "Carregando com Unstructured: /content/drive/MyDrive/InfoBio/TCC 2/databaseRag/artigos/FAQ CIRURGIA CARDIACA.docx.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "\n",
            "Carregados 3846 elementos dos documentos.\n",
            "Documentos divididos em 3938 chunks.\n",
            "Documentos divididos em 3938 chunks.\n",
            "Criando e persistindo o ChromaDB com metadados filtrados...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "Database error: error returned from database: (code: 14) unable to open database file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1428636433.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Cria DB no diretório temporário\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mvector_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_vector_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_chroma_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvector_db\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2171843154.py\u001b[0m in \u001b[0;36mcreate_vector_db\u001b[0;34m(chunks, embedding_model_name, persist_directory)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfiltered_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_complex_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#limpa os metadados dos chunks para evitar erros na criação do banco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Criando e persistindo o ChromaDB com metadados filtrados...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     db = Chroma.from_documents( #comando principal que cria o banco de dados a partir dos documentos\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiltered_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#informa quais chunks (já filtrados) devem ser adicionados ao banco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#define qual modelo de embedding será usado para vetorizar os chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/vectorstores/chroma.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0mmetadatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m         return cls.from_texts(\n\u001b[0m\u001b[1;32m    888\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m             \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/vectorstores/chroma.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mChroma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mChroma\u001b[0m \u001b[0mvectorstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \"\"\"\n\u001b[0;32m--> 817\u001b[0;31m         chroma_collection = cls(\n\u001b[0m\u001b[1;32m    818\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0membedding_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/vectorstores/chroma.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0m_client_settings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSettings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client_settings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_client_settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_client_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             self._persist_directory = (\n\u001b[1;32m    124\u001b[0m                 \u001b[0m_client_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist_directory\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpersist_directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/chromadb/__init__.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(settings, tenant, database)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mdatabase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mClientCreator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtenant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtenant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/chromadb/api/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tenant, database, settings)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Create an admin client for verifying that databases and tenants exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_admin_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdminClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_tenant_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtenant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtenant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_client_start_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/chromadb/api/client.py\u001b[0m in \u001b[0;36m_validate_tenant_database\u001b[0;34m(self, tenant, database)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;31m# Propagate ChromaErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mChromaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/chromadb/api/client.py\u001b[0m in \u001b[0;36m_validate_tenant_database\u001b[0;34m(self, tenant, database)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_tenant_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtenant\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_admin_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tenant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtenant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/chromadb/api/client.py\u001b[0m in \u001b[0;36mget_tenant\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_tenant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTenant\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tenant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/chromadb/api/rust.py\u001b[0m in \u001b[0;36mget_tenant\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_tenant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTenant\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mtenant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbindings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tenant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTenant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtenant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Database error: error returned from database: (code: 14) unable to open database file"
          ]
        }
      ],
      "source": [
        "# CÉLULA 8 (VERSÃO FINAL CORRIGIDA) - PREPARAÇÃO E CARREGAMENTO DO BANCO DE DADOS\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "from langchain_community.vectorstores import Chroma # Necessário se não estiver importado em Célula anterior\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings # Necessário se não estiver importado\n",
        "from langchain_community.docstore.document import Document # Necessário se não estiver importado\n",
        "\n",
        "# Supondo que essas funções e variáveis (LLAMA_MODEL_PATH, CHROMA_PERSIST_DIR, DATA_PATH)\n",
        "# estão definidas em células anteriores ou são variáveis globais.\n",
        "\n",
        "# Variável principal para armazenar o objeto do banco de dados\n",
        "vector_db = None\n",
        "\n",
        "# Define a pasta temporária local para criar o ChromaDB\n",
        "temp_chroma_dir = os.path.join(tempfile.gettempdir(), \"chroma_temp_db\")\n",
        "\n",
        "# --- FUNÇÕES (Requisito: Definições de load_documents_from_folder_unstructured, split_documents_into_chunks, create_vector_db, load_vector_db devem estar em células anteriores) ---\n",
        "\n",
        "# PARTE 1: Lógica de carregamento/criação do DB\n",
        "# Prioriza carregar do local final (Drive) se ele existir\n",
        "\n",
        "if os.path.exists(CHROMA_PERSIST_DIR):\n",
        "    print(\"ChromaDB existente detectado no Google Drive. Tentando carregar...\")\n",
        "    try:\n",
        "        # Tenta carregar o DB do Drive\n",
        "        vector_db = load_vector_db(persist_directory=CHROMA_PERSIST_DIR)\n",
        "        if vector_db:\n",
        "            print(\"ChromaDB carregado com sucesso do Google Drive.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao carregar ChromaDB do Google Drive: {e}\")\n",
        "        print(\"A causa pode ser permissão ou corrupção. Tentando recriar o banco de dados...\")\n",
        "        vector_db = None # Reset para forçar a criação\n",
        "\n",
        "\n",
        "if not vector_db: # Se o carregamento falhou ou o DB não existia\n",
        "    print(\"ChromaDB não encontrado ou falha ao carregar. Iniciando processo de criação em diretório temporário...\")\n",
        "\n",
        "    # Garante que o diretório temporário esteja limpo para evitar erros de escrita (Código 14)\n",
        "    if os.path.exists(temp_chroma_dir):\n",
        "        print(f\"Removendo diretório temporário antigo: {temp_chroma_dir}\")\n",
        "        shutil.rmtree(temp_chroma_dir)\n",
        "\n",
        "    # Requer as funções de carregamento e split de células anteriores\n",
        "    documents = load_documents_from_folder_unstructured(DATA_PATH)\n",
        "\n",
        "    if not documents:\n",
        "        print(f\"❌ ERRO CRÍTICO: Nenhum documento processado em {DATA_PATH}. Verifique a pasta.\")\n",
        "    else:\n",
        "        chunks = split_documents_into_chunks(documents)\n",
        "        print(f\"Documentos divididos em {len(chunks)} chunks.\")\n",
        "\n",
        "        # Cria DB no diretório temporário\n",
        "        vector_db = create_vector_db(chunks, persist_directory=temp_chroma_dir)\n",
        "\n",
        "        if vector_db:\n",
        "            print(f\"ChromaDB criado com sucesso no diretório temporário: {temp_chroma_dir}\")\n",
        "\n",
        "            # --- PONTO CRÍTICO DE CORREÇÃO ---\n",
        "            # 1. Fechar a conexão do DB antes de copiar, liberando locks do SO\n",
        "            del vector_db\n",
        "            vector_db = None\n",
        "            print(\"Conexão com o banco de dados temporário fechada.\")\n",
        "\n",
        "            # 2. Lógica de cópia para o Google Drive\n",
        "            print(f\"Copiando ChromaDB do diretório temporário para o Google Drive: {CHROMA_PERSIST_DIR}\")\n",
        "\n",
        "            if os.path.exists(CHROMA_PERSIST_DIR):\n",
        "                 print(f\"Removendo conteúdo existente em {CHROMA_PERSIST_DIR} antes de copiar.\")\n",
        "                 shutil.rmtree(CHROMA_PERSIST_DIR)\n",
        "            try:\n",
        "                # Copia o DB para o Drive\n",
        "                shutil.copytree(temp_chroma_dir, CHROMA_PERSIST_DIR)\n",
        "                print(\"Cópia para o Google Drive concluída com sucesso.\")\n",
        "\n",
        "                # 3. Recarregar o DB diretamente do Drive para uso subsequente\n",
        "                vector_db = load_vector_db(persist_directory=CHROMA_PERSIST_DIR)\n",
        "\n",
        "            except Exception as e:\n",
        "                 print(f\"❌ ERRO ao copiar ou recarregar do Google Drive: {e}\")\n",
        "                 vector_db = None # Garante que o estado final seja de erro se o DB não persistir\n",
        "        else:\n",
        "            print(\"\\n❌ Falha na criação do ChromaDB no diretório temporário.\")\n",
        "\n",
        "\n",
        "# PARTE 2: Verificação final\n",
        "if vector_db:\n",
        "    print(\"\\n✅ Ambiente pronto! A variável 'vector_db' foi carregada/criada com sucesso.\")\n",
        "    print(\"   Prossiga para a Célula 9 (Console) ou Célula 10 (Gradio).\")\n",
        "else:\n",
        "    print(\"\\n❌ ERRO CRÍTICO: Falha ao preparar o banco de dados vetorial. O chatbot não pode iniciar.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZviSw1i3n_V"
      },
      "outputs": [],
      "source": [
        "# CÉLULA 10 (VERSÃO FINAL CORRIGIDA) - INTERFACE DE CHAT (VERSÃO WEB COM GRADIO)\n",
        "\n",
        "# Garante que o Gradio está instalado\n",
        "!pip install -q gradio\n",
        "\n",
        "import gradio as gr\n",
        "import os\n",
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# --- Função para configurar a cadeia RAG para a interface ---\n",
        "# Recebe o objeto do prompt pronto para evitar erros de validação.\n",
        "def setup_rag_chain_for_gradio(vector_db, llm_model_path, prompt_object):\n",
        "    llm_gradio = LlamaCpp(\n",
        "        model_path=llm_model_path,\n",
        "        temperature=0.2, # mais focado, menos criativo para respostas + precisas\n",
        "        max_tokens=1024,\n",
        "        n_ctx=8192,\n",
        "        n_gpu_layers=-1, # tenta usar a GPU para máxima aceleração\n",
        "        verbose=False,\n",
        "        streaming=True   # Mantém o streaming para gerar a resposta em tempo real\n",
        "    )\n",
        "\n",
        "    retriever = vector_db.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={\"k\": 5, \"fetch_k\": 20}\n",
        "    )\n",
        "\n",
        "    # A cadeia agora usa o objeto do prompt que foi passado diretamente\n",
        "    qa_chain_gradio = RetrievalQA.from_chain_type(\n",
        "        llm=llm_gradio,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True,\n",
        "        chain_type_kwargs={\"prompt\": prompt_object}\n",
        "    )\n",
        "    return qa_chain_gradio\n",
        "\n",
        "# --- Função que o Gradio vai chamar para cada mensagem do usuário ---\n",
        "def chat_function(message, history):\n",
        "    print(f\"Pergunta recebida pela interface: {message}\")\n",
        "\n",
        "    # O método .stream retorna um \"gerador\" que produz os tokens da resposta um por um\n",
        "    response_generator = qa_chain_for_ui.stream({\"query\": message})\n",
        "\n",
        "    full_response = \"\"\n",
        "    # Iteramos sobre o gerador para construir a resposta em tempo real na interface\n",
        "    for chunk in response_generator:\n",
        "        # A resposta do LLM vem na chave 'result'\n",
        "        if 'result' in chunk:\n",
        "            token = chunk['result']\n",
        "            full_response += token\n",
        "            yield full_response # 'yield' envia o texto atualizado para a UI do Gradio\n",
        "\n",
        "# --- Lógica principal para lançar a interface ---\n",
        "# Verifica se o banco de dados (da Célula 8) e o modelo LLM estão prontos\n",
        "if 'vector_db' in locals() and vector_db and os.path.exists(LLAMA_MODEL_PATH):\n",
        "    print(\"Configurando a cadeia RAG para a interface Gradio...\")\n",
        "\n",
        "    # 1. Definimos a string completa do template do prompt (CORRIGIDO: Removido indentação extra)\n",
        "    prompt_template_string = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "Você é um profissional de saúde, especialista em orientação pré e pós-operatória de cirurgia cardíaca. Forneça respostas padronizadas, seguras, objetivas e em linguagem acessível ao paciente. **Nunca mencione que está buscando em documentos, base de conhecimento ou contexto.** Mantenha um tom humano e profissional. Se a informação for individualizada (como dosagem, diagnóstico ou liberação para atividades) ou não estiver no contexto, responda com uma das seguintes frases padronizadas: 'Esta é uma questão específica do seu histórico médico e deve ser discutida diretamente com seu médico cardiologista ou a equipe de enfermagem.' OU 'Essa informação depende de uma avaliação individualizada. Por favor, consulte seu médico ou a equipe de saúde responsável.'\n",
        "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "Com base no contexto abaixo, responda à minha pergunta.\n",
        "\n",
        "Contexto:\n",
        "{context}\n",
        "\n",
        "Pergunta:\n",
        "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "\n",
        "    # 2. Criamos o objeto PromptTemplate fora da função (CORRIGIDO: Corrigido o nome da variável de prompt)\n",
        "    PROMPT_FOR_GRADIO = PromptTemplate(\n",
        "        template=prompt_template_string,\n",
        "        input_variables=[\"context\", \"question\"]\n",
        "    )\n",
        "\n",
        "    # 3. Passamos o objeto já pronto para a função de configuração\n",
        "    qa_chain_for_ui = setup_rag_chain_for_gradio(vector_db, LLAMA_MODEL_PATH, PROMPT_FOR_GRADIO)\n",
        "\n",
        "    print(\"Cadeia RAG pronta.\")\n",
        "\n",
        "    print(\"\\n🚀 Lançando a interface do Gradio...\")\n",
        "    print(\"Aguarde os links aparecerem. Clique no link PÚBLICO (Public URL) para abrir e compartilhar.\")\n",
        "\n",
        "    # 4. Chamada do ChatInterface\n",
        "    chat_interface = gr.ChatInterface(\n",
        "        fn=chat_function,\n",
        "        title=\"🤖 Chatbot de Orientação Cardíaca\",\n",
        "        description=\"Faça uma pergunta sobre cuidados pré ou pós-operatórios cardíacos.\",\n",
        "        examples=[[\"Quais os cuidados com a ferida operatória?\"], [\"Posso dirigir após a cirurgia?\"], [\"Como devo me alimentar antes da cirurgia?\"]],\n",
        "        theme=\"soft\"\n",
        "    )\n",
        "\n",
        "    # Lança a interface, gerando o link público para compartilhamento\n",
        "    chat_interface.launch(share=True, debug=True)\n",
        "\n",
        "else:\n",
        "    print(\"❌ ERRO: Execute a Célula 8 primeiro para preparar o ambiente (vector_db).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dj9Q44x73gwg"
      },
      "outputs": [],
      "source": [
        "# CÉLULA 9- INTERFACE DE CHAT (VERSÃO CONSOLE - OPCIONAL)\n",
        "\n",
        "if vector_db and os.path.exists(LLAMA_MODEL_PATH):\n",
        "    # Configura a cadeia RAG para o console (com o callback de streaming original)\n",
        "    qa_chain_console = setup_rag_chain(vector_db, LLAMA_MODEL_PATH)\n",
        "\n",
        "    print(\"\\n======================================================================\")\n",
        "    print(\"Chatbot de Orientação Cardíaca (digite 'sair' para encerrar)\")\n",
        "    print(\"======================================================================\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"\\nSua pergunta: \")\n",
        "        if user_query.lower() == 'sair':\n",
        "            print(\"Encerrando o chatbot. Até logo!\")\n",
        "            break\n",
        "\n",
        "        print(\"\\nResposta: \", end=\"\", flush=True)\n",
        "        # O streaming é tratado pelo callback dentro de setup_rag_chain\n",
        "        result = qa_chain_console.invoke({\"query\": user_query})\n",
        "\n",
        "        # Impressão das fontes\n",
        "        print(\"\\n\\n---\")\n",
        "        print(\"Fontes consultadas:\")\n",
        "        sources = {os.path.basename(doc.metadata.get('source', 'N/A')) for doc in result['source_documents']}\n",
        "        for source in sorted(list(sources)):\n",
        "            print(f\"- {source}\")\n",
        "        print(\"---\")\n",
        "else:\n",
        "    print(\"❌ Execute a Célula 8 primeiro para preparar o ambiente.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}